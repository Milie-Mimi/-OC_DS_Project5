{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "133b95a6",
   "metadata": {},
   "source": [
    "# Projet 5: Segmentez les clients d'un site e-commerce (analyse exploratoire)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cefc99",
   "metadata": {},
   "source": [
    "Objectifs: \n",
    "- comprendre les différents **types d'utilisateurs** grâce à leur **comportement** et **données personnelles** => utilisation de méthodes **non supervisées** pour regrouper les clients de profils similaires\n",
    "- créer une **segmentation des clients** que la société Olist pourra utiliser pour ses **campagnes de communication**. La segmentation proposée doit être exploitable et facile d’utilisation par l'équipe Marketing. Elle doit au minimum pouvoir différencier les **bons et moins bons clients en termes de commandes et de satisfaction**.\n",
    "- fournir à l’équipe marketing une **description actionable de la segmentation et de sa logique sous-jacente** pour une utilisation optimale, ainsi qu’une proposition de **contrat de maintenance** basée sur une analyse de la **stabilité des segments au cours du temps**. Une recommandation de fréquence à laquelle la segmentation doit être mise à jour pour rester pertinente doit être faite afin de pouvoir rédiger le devis de contrat de maintenance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b22a0e",
   "metadata": {},
   "source": [
    "## Table des matières: <a class=\"anchor\" id=\"0\"></a>\n",
    "\n",
    "1. [Import des librairies et configurations générales](#library)\n",
    "2. [Chargement et visualisation des données](#data)\n",
    "3. [Consolidation des données (par order_id)](#conso)\n",
    "4. [Consolidation des données (par customer_unique_id)](#tab_cli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602434ef",
   "metadata": {},
   "source": [
    "## Import des librairies et configurations générales <a class=\"anchor\" id=\"library\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b36b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour vérifier si la convention PEP8 est respectée\n",
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ccbfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import unidecode  # caractères spéciaux\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Configuration générale des graphiques\n",
    "parameters = {'axes.labelsize': 13,\n",
    "              'axes.titlesize': 16,\n",
    "              'axes.titleweight': 'bold'}\n",
    "plt.rcParams.update(parameters)\n",
    "\n",
    "# Modification de l'affichage des lignes et colonnes pour plus de lisibilité\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# pd.options.display.float_format = '{:20,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c5256d",
   "metadata": {},
   "source": [
    "## Chargement et visualisation des données <a class=\"anchor\" id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4cdbb5",
   "metadata": {},
   "source": [
    "Olist nous fournit une **base de données anonymisée** comportant des informations sur:\n",
    "\n",
    "- l’historique de commandes, \n",
    "- les produits achetés, \n",
    "- les commentaires de satisfaction, \n",
    "- et la localisation des clients depuis janvier 2017\n",
    "\n",
    "Seuls les 3% des clients qui ont réalisé plusieurs commandes nous intéressent.\n",
    "\n",
    "A noter que le code fourni doit respecter la convention PEP8 pour être exploité par Olist. Quelques exemples de conventions à respecter:\n",
    "- encodage UTF-8\n",
    "- indentation de 4 caractères\n",
    "- 79 caractères par ligne\n",
    "- imports à déclarer au début du script\n",
    "\n",
    "Nous allons dans cette partie charger les données de chaque dataset afin de comprendre quelles sont celles qui pourront nous être utiles pour identifier les différents types d'utilisateurs.\n",
    "\n",
    "Nous vérifierons les également les lignes qui apparaissent plusieurs fois sur les clefs de jointures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdd9458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des datasets\n",
    "customers = pd.read_csv('data/olist_customers_dataset.csv',\n",
    "                        sep=',',\n",
    "                        encoding='utf-8')\n",
    "customers.name = 'customers'\n",
    "\n",
    "geo = pd.read_csv('data/olist_geolocation_dataset.csv',\n",
    "                  sep=',',\n",
    "                  encoding='utf-8')\n",
    "geo.name = 'geo'\n",
    "\n",
    "items = pd.read_csv('data/olist_order_items_dataset.csv',\n",
    "                    sep=',',\n",
    "                    encoding='utf-8')\n",
    "items.name = 'items'\n",
    "\n",
    "payments = pd.read_csv('data/olist_order_payments_dataset.csv',\n",
    "                       sep=',',\n",
    "                       encoding='utf-8')\n",
    "payments.name = 'payments'\n",
    "\n",
    "reviews = pd.read_csv('data/olist_order_reviews_dataset.csv',\n",
    "                      sep=',',\n",
    "                      encoding='utf-8')\n",
    "reviews.name = 'reviews'\n",
    "\n",
    "orders = pd.read_csv('data/olist_orders_dataset.csv',\n",
    "                     sep=',',\n",
    "                     encoding='utf-8')\n",
    "orders.name = 'orders'\n",
    "\n",
    "products = pd.read_csv('data/olist_products_dataset.csv',\n",
    "                       sep=',',\n",
    "                       encoding='utf-8')\n",
    "products.name = 'products'\n",
    "\n",
    "sellers = pd.read_csv('data/olist_sellers_dataset.csv',\n",
    "                      sep=',',\n",
    "                      encoding='utf-8')\n",
    "sellers.name = 'sellers'\n",
    "\n",
    "category = pd.read_csv('data/product_category_name_translation.csv',\n",
    "                       sep=',',\n",
    "                       encoding='utf-8')\n",
    "category.name = 'category'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d031c5",
   "metadata": {},
   "source": [
    "**Architecture des données**\n",
    "<img src=\"data\\Data_Scheme.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b22d5",
   "metadata": {},
   "source": [
    "### olist_customers_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad99c9f",
   "metadata": {},
   "source": [
    "Ce jeu de données contient des informations sur le **client** et son **emplacement**. Il permet **d'identifier les clients uniques dans l'ensemble de données des commandes** et pour trouver le **lieu de livraison des commandes**.\n",
    "\n",
    "Le même client aura des identifiants différents pour des commandes différentes. Le but d'avoir un customer_unique_id dans l'ensemble de données est de permettre **d'identifier les clients qui ont fait des réachats au magasin**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defc590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des 5 premières lignes du dataset\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaca46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_total_nan(dataframe):\n",
    "    '''Fonction qui retourne le nombre de lignes,\n",
    "    de variables, le nombre total de valeurs manquantes et\n",
    "    le pourcentage associé'''\n",
    "    missing = dataframe.isna().sum().sum()\n",
    "    missing_percent = round(missing\n",
    "                            / (dataframe.shape[0] * dataframe.shape[1])\n",
    "                            * 100,\n",
    "                            2)\n",
    "\n",
    "    print(f\"Nombre de lignes: {dataframe.shape[0]}\")\n",
    "    print(f\"Nombre de colonnes: {dataframe.shape[1]}\")\n",
    "    print(f\"Nombre total de NaN du dataset: {missing}\")\n",
    "    print(f\"% total de NaN du dataset: {missing_percent}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf7923",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_total_nan(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb6ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_variables(data):\n",
    "    ''' Fonction qui prend un dataframe en entrée, et retourne un\n",
    "    récapitulatif qui contient le nom des variables, leur type, un\n",
    "    exemple de modalité, le nombre total de lignes, le nombre et\n",
    "    pourcentage de valeurs distinctes, le nombre et pourcentage de\n",
    "    valeurs non manquantes et de valeurs manquantes (NaN) et les\n",
    "    principales statistiques pour les variables numériques (moyenne,\n",
    "    médiane, distribution, variance, écart type, minimum, quartiles et\n",
    "    maximum)'''\n",
    "\n",
    "    # Choix du nom des variables à afficher\n",
    "    df = pd.DataFrame(columns=[\n",
    "        'Variable name', 'Variable type', 'Example', 'Raws', 'Distinct',\n",
    "        '% distinct', 'Not NaN', '% Not NaN', 'NaN', '% NaN', 'Mean',\n",
    "        'Median', 'Skew', 'Kurtosis', 'Variance', 'Std', 'Min', '25%',\n",
    "        '75%', 'Max'\n",
    "    ])\n",
    "\n",
    "    # Pour chaque colonne du dataframe\n",
    "    for col in data.columns:\n",
    "\n",
    "        # Définition des variables\n",
    "        # type de la variable (object, float, int...)\n",
    "        var_type = data[col].dtypes\n",
    "        # premier élément notNA\n",
    "        example = data[data[col].notna()][col].iloc[0]\n",
    "        # nombre total de lignes\n",
    "        nb_raw = len(data[col])\n",
    "        # nombre de valeurs non manquantes\n",
    "        count = len(data[col]) - data[col].isna().sum()\n",
    "        # % de valeurs non manquantes\n",
    "        percent_count = round(data[col].notnull().mean(), 4)*100\n",
    "        # nombre de modalités que peut prendre la variable\n",
    "        distinct = data[col].nunique()\n",
    "        # % de valeurs distinctes\n",
    "        percent_distinct = round(data[col].nunique()/len(data[col]), 4)\n",
    "        percent_distinct = percent_distinct * 100\n",
    "        # nombre de valeurs manquantes\n",
    "        missing = data[col].isna().sum()\n",
    "        # % de valeurs manquantes\n",
    "        percent_missing = round(data[col].isna().mean(), 4)*100\n",
    "\n",
    "        # Pour les var de type 'int' ou 'float': on remplit toutes les col\n",
    "        if var_type == 'int32' or var_type == 'int64' or var_type == 'float':\n",
    "            df = pd.concat([df, pd.DataFrame([[col, var_type, example, nb_raw,\n",
    "                                               distinct, percent_distinct,\n",
    "                                               count,\n",
    "                                               percent_count,\n",
    "                                               missing,\n",
    "                                               percent_missing,\n",
    "                                               round(data[col].mean(), 2),\n",
    "                                               round(data[col].median(), 2),\n",
    "                                               round(data[col].skew(), 2),\n",
    "                                               round(data[col].kurtosis(), 2),\n",
    "                                               round(data[col].var(), 2),\n",
    "                                               round(data[col].std(), 2),\n",
    "                                               round(data[col].min(), 2),\n",
    "                                               round(data[col].quantile(0.25),\n",
    "                                                     2),\n",
    "                                               round(data[col].quantile(0.75),\n",
    "                                                     2),\n",
    "                                               data[col].max()]],\n",
    "                                             columns=['Variable name',\n",
    "                                                      'Variable type',\n",
    "                                                      'Example',\n",
    "                                                      'Raws',\n",
    "                                                      'Distinct',\n",
    "                                                      '% distinct',\n",
    "                                                      'Not NaN',\n",
    "                                                      '% Not NaN',\n",
    "                                                      'NaN',\n",
    "                                                      '% NaN',\n",
    "                                                      'Mean',\n",
    "                                                      'Median',\n",
    "                                                      'Skew',\n",
    "                                                      'Kurtosis',\n",
    "                                                      'Variance',\n",
    "                                                      'Std',\n",
    "                                                      'Min',\n",
    "                                                      '25%',\n",
    "                                                      '75%',\n",
    "                                                      'Max'])])\n",
    "\n",
    "            # Pour les variables d'un autre type: on ne remplit que\n",
    "            # les variables de compte\n",
    "\n",
    "        else:\n",
    "            df = pd.concat([df, pd.DataFrame([[col, var_type, example,\n",
    "                                               nb_raw, distinct,\n",
    "                                               percent_distinct,\n",
    "                                               count,\n",
    "                                               percent_count, missing,\n",
    "                                               percent_missing,\n",
    "                                               '', '', '', '', '', '',\n",
    "                                               '', '', '', '']],\n",
    "                                             columns=['Variable name',\n",
    "                                                      'Variable type',\n",
    "                                                      'Example',\n",
    "                                                      'Raws',\n",
    "                                                      'Distinct',\n",
    "                                                      '% distinct',\n",
    "                                                      'Not NaN',\n",
    "                                                      '% Not NaN',\n",
    "                                                      'NaN',\n",
    "                                                      '% NaN',\n",
    "                                                      'Mean',\n",
    "                                                      'Median',\n",
    "                                                      'Skew',\n",
    "                                                      'Kurtosis',\n",
    "                                                      'Variance',\n",
    "                                                      'Std',\n",
    "                                                      'Min',\n",
    "                                                      '25%',\n",
    "                                                      '75%',\n",
    "                                                      'Max'])])\n",
    "\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240a8b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "describe_variables(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686084d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de doublons totaux\n",
    "print(f\"Lignes en doublons: {customers.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a02a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de commandes par customer_unique_id\n",
    "customers_orders = customers[\"customer_unique_id\"].value_counts()\n",
    "\n",
    "print(\"Nb de commandes par client (> 2 commandes)\")\n",
    "customers_orders[customers_orders > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68101403",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- aucune valeur manquante\n",
    "- la variable customer_id ne comporte que des éléments uniques\n",
    "- certains customer_unique_id apparaissent sur plusieurs lignes du dataset correspondant à des commandes différentes\n",
    "- ce dataset est relié au dataset geolocation par la clef zip_code_prefix et au dataset orders par la clef customer_id%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce5703",
   "metadata": {},
   "source": [
    "### olist_geolocation_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e1c90a",
   "metadata": {},
   "source": [
    "Ce jeu de données contient des informations sur les **codes postaux** brésiliens et leurs coordonnées **lat/lng**. Il permet de calculer la distance entre le vendeur et le client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des 5 premières lignes du dataset\n",
    "geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f69a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape du dataset\n",
    "shape_total_nan(geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae440f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description des variables\n",
    "describe_variables(geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db89f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublons totaux\n",
    "print(f\"Lignes en doublons: {geo.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des doublons intégraux\n",
    "geo = geo.drop_duplicates()\n",
    "geo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f914f1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de lignes ayant le même zip_code_prefix\n",
    "print(f\"Nb lignes: {geo.duplicated('geolocation_zip_code_prefix').sum()}\")\n",
    "\n",
    "# Récupération des zip_code_prefix qui apparaissent plusieurs fois\n",
    "zip_code_dup = geo[geo.duplicated('geolocation_zip_code_prefix')][\n",
    "    'geolocation_zip_code_prefix'].unique()\n",
    "\n",
    "# Filtrage du dataset sur ces zip_code_prefix\n",
    "geo_dup = geo[geo['geolocation_zip_code_prefix'].isin(\n",
    "    zip_code_dup)].sort_values(\n",
    "    by='geolocation_zip_code_prefix')\n",
    "geo_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7f4e4d",
   "metadata": {},
   "source": [
    "Un même zip_code prefix peut avoir différentes latitudes et longitudes. Afin d'avoir des zip_codes uniques, nous allons calculer la moyenne des latitudes et longitudes par code postal puis récupérer la ville et l'état:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02081efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyenne des lat et lon par code postal\n",
    "zip_mean = geo.groupby('geolocation_zip_code_prefix')[\n",
    "    ['geolocation_lat', 'geolocation_lng']].mean()\n",
    "\n",
    "# On conserve une ville par code postal\n",
    "zip_city = geo[['geolocation_zip_code_prefix',\n",
    "                'geolocation_city',\n",
    "                'geolocation_state']].groupby(\n",
    "    ['geolocation_zip_code_prefix',\n",
    "     'geolocation_city',\n",
    "     'geolocation_state']).count().reset_index()\n",
    "\n",
    "zip_city = zip_city.drop_duplicates('geolocation_zip_code_prefix',\n",
    "                                    keep='first')\n",
    "\n",
    "# Merge\n",
    "geo = pd.merge(left=zip_mean, right=zip_city,\n",
    "               how='left', on='geolocation_zip_code_prefix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28a0530",
   "metadata": {},
   "source": [
    "Le dataset contenant 27 états distincts, nous allons réduire le nombre de modalités en les regroupant en zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modalités de geolocation_state\n",
    "geo['geolocation_state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79eebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du dictionnaire des zones\n",
    "ZONES = {\n",
    "    'PA': 'Nord',\n",
    "    'AP': 'Nord',\n",
    "    'RR': 'Nord',\n",
    "    'SE': 'Nord_Est',\n",
    "    'PE': 'Nord_Est',\n",
    "    'RN': 'Nord_Est',\n",
    "    'AL': 'Nord_Est',\n",
    "    'PB': 'Nord_Est',\n",
    "    'CE': 'Nord_Est',\n",
    "    'PI': 'Nord_Est',\n",
    "    'MA': 'Nord_Est',\n",
    "    'AM': 'Nord_Ouest',\n",
    "    'AC': 'Nord_Ouest',\n",
    "    'DF': 'Centre',\n",
    "    'GO': 'Centre',\n",
    "    'TO': 'Centre',\n",
    "    'MT': 'Centre',\n",
    "    'BA': 'Centre_Est',\n",
    "    'RO': 'Centre_Ouest',\n",
    "    'PR': 'Sud',\n",
    "    'SC': 'Sud',\n",
    "    'RS': 'Sud',\n",
    "    'SP': 'Sud_Est',\n",
    "    'RJ': 'Sud_Est',\n",
    "    'ES': 'Sud_Est',\n",
    "    'MG': 'Sud_Est',\n",
    "    'MS': 'Sud_Ouest',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d5afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_words(values, dictionary):\n",
    "    result = []\n",
    "    for lib in values:\n",
    "        categ = \"AUTRE\"\n",
    "        for word, val in dictionary.items():\n",
    "            if word in lib:\n",
    "                categ = val\n",
    "        result.append(categ)\n",
    "    return result\n",
    "\n",
    "\n",
    "geo[\"zone\"] = detect_words(geo[\"geolocation_state\"], ZONES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65571d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de tuples lat / lon\n",
    "geo['lat_lon'] = list(zip(geo['geolocation_lat'], geo['geolocation_lng']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fd755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geo['point'] = geo.apply(lambda row: Point(latitude=row['geolocation_lat'],\n",
    "#                                           longitude=row['geolocation_lng']),\n",
    "#                         axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e509b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "geo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e00ecdd",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- aucune valeur manquante\n",
    "- un grand nombre de lignes en doublons qui ont été supprimées\n",
    "- d'après l'architecture des données, le zip_code_prefix est la clef qui fait le lien avec les datasets customers et sellers\n",
    "- ce dataset est dorénavant composé d'une observation par code postal\n",
    "- un colonne 'zone' avec moins de modalités et regroupant plusieurs states a été crééé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3459b24b",
   "metadata": {},
   "source": [
    "### olist_order_items_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20d2c88",
   "metadata": {},
   "source": [
    "Ce dataset inclut les informations sur éléments achetés de chaque commande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f1a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des premières lignes du dataset\n",
    "items.sort_values(by='product_id').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14288746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape du dataset\n",
    "shape_total_nan(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19603f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description des variables\n",
    "describe_variables(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c83b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublons totaux\n",
    "print(f\"Lignes en doublons: {items.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b2fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de lignes ayant le même order_id\n",
    "print(f\"Nb lignes: {items.duplicated(['order_id']).sum()}\")\n",
    "\n",
    "# Récupération des order_id qui apparaissent plusieurs fois\n",
    "order_id_dup = items[items.duplicated('order_id')][\n",
    "    'order_id'].unique()\n",
    "\n",
    "# Filtrage du dataset sur ces order_id\n",
    "items_dup = items[items['order_id'].isin(\n",
    "    order_id_dup)].sort_values(\n",
    "    by='order_id')\n",
    "items_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557d8c75",
   "metadata": {},
   "source": [
    "Un même order_id peut apparaitre plusieurs fois, c'est à dire à chaque fois qu'un article est rajouté dans la commande. Il ne s'agit pas de doublons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a20c44",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- aucune valeur manquante\n",
    "- d'après l'architecture des données, le seller_id est la clef qui fait le lien avec le dataset sellers, order_id avec le dataset orders et product_id avec le dataset products\n",
    "- il existe plusieurs lignes pour un même order_id, il s'agit des différents produits rajoutés dans la commande"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f979617f",
   "metadata": {},
   "source": [
    "Afin de pouvoir ensuite merger cette table avec celle des commandes tout en ayant une observation par commande, nous allons regrouper les lignes par order_id et créer les indicateurs qui nous intéressent:\n",
    "- nombre d'articles achetés\n",
    "- nombre d'articles différents achetés\n",
    "- produit le plus acheté\n",
    "- nombre de vendeurs\n",
    "- vendeur préféré\n",
    "- prix total des articles\n",
    "- prix du transport\n",
    "- prix de l'article le moins cher\n",
    "- prix de l'article le plus cher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c17756",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_merge = items.groupby(['order_id'],\n",
    "                            as_index=False,\n",
    "                            dropna=False).agg(\n",
    "    nb_art=('order_item_id', 'max'),\n",
    "    nb_art_diff=('product_id', 'nunique'),\n",
    "    art_pref=('product_id', lambda x: x.mode()[0]),\n",
    "    nb_vendeurs=('seller_id', 'nunique'),\n",
    "    vendeur_pref=('seller_id', lambda x: x.mode()[0]),\n",
    "    prix_tot_art=('price', 'sum'),\n",
    "    prix_transport=('freight_value', 'sum'),\n",
    "    prix_art_min=('price', 'min'),\n",
    "    prix_art_max=('price', 'max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eeaae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification que la table contient bien une ligne par commande\n",
    "items_merge.shape[0] == items['order_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075db3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1c4c95",
   "metadata": {},
   "source": [
    "### olist_order_payments_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f969c1",
   "metadata": {},
   "source": [
    "Ce dataset contient les informations sur les options de paiement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6ffb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des 5 premières lignes du dataset\n",
    "payments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape du dataset\n",
    "shape_total_nan(payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622acaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description des variables\n",
    "describe_variables(payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff22469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublons totaux\n",
    "print(f\"Lignes en doublons: {payments.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b525bfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Nombre de lignes ayant le même order_id\n",
    "print(f\"Nb lignes: {payments.duplicated(['order_id']).sum()}\")\n",
    "\n",
    "# Récupération des order_id qui apparaissent plusieurs fois\n",
    "order_id_dup = payments[payments.duplicated('order_id')][\n",
    "    'order_id'].unique()\n",
    "\n",
    "# Filtrage du dataset sur ces order_id\n",
    "payments_dup = payments[payments['order_id'].isin(\n",
    "    order_id_dup)].sort_values(\n",
    "    by='order_id')\n",
    "payments_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23084be9",
   "metadata": {},
   "source": [
    "Une même commande peut apparaitre sur plusieurs lignes. C'est le cas lorsque le client a payé avec 2 méthodes différentes. La variable payment_installments correspond au nombre de versements effectués par type de paiment. Il ne s'agit donc pas de doublons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f1fb93",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- aucune valeur manquante\n",
    "- d'après l'architecture des données, l'order_id est la clef qui fait le lien avec le dataset orders\n",
    "- order_id apparait sur plusieurs lignes lorsque le client a utilisé différents moyens de paiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a8acb",
   "metadata": {},
   "source": [
    "Afin de pouvoir ensuite merger cette table avec celle des commandes tout en ayant une observation par commande, nous allons regrouper les lignes par order_id et créer les indicateurs qui nous intéressent:\n",
    "- nombre maximum de facilités de paiement par commande\n",
    "- moyen de paiement préféré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6945c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_pivot = payments.pivot(index=['order_id',\n",
    "                                       'payment_sequential',\n",
    "                                       'payment_installments'],\n",
    "                                columns='payment_type',\n",
    "                                values='payment_value').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26495333",
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_merge = payments_pivot.groupby(['order_id'],\n",
    "                                        as_index=False,\n",
    "                                        dropna=False).agg(\n",
    "    facil_paiement_max=('payment_installments', 'max'),\n",
    "    boleto=('boleto', 'sum'),\n",
    "    credit_card=('credit_card', 'sum'),\n",
    "    debit_card=('debit_card', 'sum'),\n",
    "    not_defined=('not_defined', 'sum'),\n",
    "    voucher=('voucher', 'sum'))\n",
    "\n",
    "payments_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05150804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification que la table contient bien une ligne par commande\n",
    "payments_merge.shape[0] == payments['order_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd62fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_merge['moy_paiement_pref'] = payments_merge[['boleto',\n",
    "                                                      'credit_card',\n",
    "                                                      'debit_card',\n",
    "                                                      'not_defined',\n",
    "                                                      'voucher']].idxmax(\n",
    "    axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6faaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "payments_merge = payments_merge[['order_id', 'facil_paiement_max',\n",
    "                                 'moy_paiement_pref']]\n",
    "payments_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45f8508",
   "metadata": {},
   "source": [
    "### olist_order_reviews_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006a9ef",
   "metadata": {},
   "source": [
    "Ce dataset contient les informations sur les commentaires des clients.\n",
    "\n",
    "Après qu'un client ait acheté un produit sur Olist Store, le vendeur est informé qu'il doit exécuter la commande. Une fois que le client a reçu le produit, ou que la date de livraison estimée est arrivée, le client reçoit une enquête de satisfaction par e-mail où il peut donner une note sur l'expérience d'achat et écrire quelques commentaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f3449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des 5 premières lignes du dataset\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape du dataset\n",
    "shape_total_nan(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description des variables\n",
    "describe_variables(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a30386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublons totaux\n",
    "print(f\"Lignes en doublons: {reviews.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b2959",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Doublons sur la clef order_id\n",
    "print(f\"Nb lignes: {reviews.duplicated('order_id').sum()}\")\n",
    "\n",
    "# Récupération des order_id qui apparaissent plusieurs fois\n",
    "order_id_dup = reviews[reviews.duplicated('order_id')]['order_id'].unique()\n",
    "\n",
    "# Filtrage du dataset sur ces order_id\n",
    "reviews_dup = reviews[reviews['order_id'].isin(order_id_dup)].sort_values(\n",
    "    by='order_id')\n",
    "reviews_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705fb2c7",
   "metadata": {},
   "source": [
    "Une même clef de jointure order_id existe plusieurs fois dans le dataset. Nous allons essayer de comprendre et de trouver une stratégie pour traiter ces doublons.\n",
    "\n",
    "Stratégie de traitement des order_id_dupliqués:\n",
    "- Completion des variables review_comment_message et review_comment_title NaN lorsque l'information existe sur une autre ligne\n",
    "- On garde la date du commentaire la plus récente (review_answer_timestamp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbe09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(dataframe, var_to_map, var_mapping):\n",
    "    table_mapping = dataframe.groupby(\n",
    "        [var_mapping, var_to_map])['review_id'].count().reset_index()\n",
    "    table_mapping = table_mapping.sort_values(var_to_map,\n",
    "                                              ascending=True)  # sur col txt\n",
    "    table_mapping = table_mapping.drop_duplicates(subset=var_mapping,\n",
    "                                                  # first car nan after\n",
    "                                                  keep='first')\n",
    "\n",
    "    # Merge du dataframe avec la table de mapping\n",
    "    df = pd.merge(left=dataframe, right=table_mapping[[var_mapping,\n",
    "                                                       var_to_map]],\n",
    "                  how=\"left\", on=var_mapping)\n",
    "\n",
    "    # Lorsque la var_to_map est NaN, je complète avec la valeur du mapping\n",
    "    df[f'{var_to_map}_x'] = np.where(df[f'{var_to_map}_x'].isnull(),\n",
    "                                     df[f'{var_to_map}_y'],\n",
    "                                     df[f'{var_to_map}_x'])\n",
    "\n",
    "    # On supprime la variable issue de la jointure et on enlève le suffixe _x\n",
    "    df.rename(columns={f'{var_to_map}_x': var_to_map}, inplace=True)\n",
    "    df.drop(f'{var_to_map}_y', axis='columns', inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b91005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completion des variables ayant le même order_id\n",
    "reviews = mapping(reviews, 'review_comment_message', 'order_id')\n",
    "reviews = mapping(reviews, 'review_comment_title', 'order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aeb1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des order_id dupliqués en conservant celui\n",
    "# qui a le commentaire le plus récent\n",
    "reviews = reviews.sort_values(by='review_answer_timestamp',\n",
    "                              ascending=False).drop_duplicates('order_id',\n",
    "                                                               keep='first')\n",
    "\n",
    "# Doublons sur la clef order_id\n",
    "print(f\"Lignes en doublons: {reviews.duplicated('order_id').sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd5463",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- valeurs manquantes sur les variables sur les titres et commentaires des questionnaires de satisfaction envoyés aux clients\n",
    "- d'après l'architecture des données, l'order_id est la clef qui fait le lien avec le dataset orders\n",
    "- doublons sur l'order_id retraités en completant les valeurs manquantes puis conservant la date de commentaire la plus récente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0e9bb",
   "metadata": {},
   "source": [
    "### olist_orders_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537b2a58",
   "metadata": {},
   "source": [
    "Dataset principal sur les commandes passées par les différents clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des 5 premières lignes du dataset\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d290f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape du dataset\n",
    "shape_total_nan(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61df9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description des variables\n",
    "describe_variables(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870ff3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublons totaux\n",
    "print(f\"Lignes en doublons: {orders.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acf8b79",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- quelques valeurs manquantes sur les variables order_approved_at, order_delivered_carrier_date et order_delivered_customer_date ce qui semble cohérent. En effet, une commande peut ne pas avoir été validée ou livrée.\n",
    "- d'après l'architecture des données, l'order_id est la clef qui fait le lien avec les datasets order_payments, order_reviews et order_items => pas de doublons\n",
    "- customer_id est la clef qui fait le lien avec order_customer => pas de doublons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e78a511",
   "metadata": {},
   "source": [
    "### olist_products_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a6c91c",
   "metadata": {},
   "source": [
    "Dataset rassemblant tous les produits vendus par Olist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc1c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des 5 premières lignes du dataset\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e93c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape du dataset\n",
    "shape_total_nan(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef61722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description des variables\n",
    "describe_variables(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00834a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublons totaux\n",
    "print(f\"Lignes en doublons: {products.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c854a0",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- quelques valeurs manquantes\n",
    "- product_id est la clef qui fait le lien avec le dataset products => pas de doublons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067106c2",
   "metadata": {},
   "source": [
    "Nous ne conservons pour le merge avec la table consolidée que les variables product_id et product_category_name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2d8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_merge = products[['product_id', 'product_category_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4ed935",
   "metadata": {},
   "source": [
    "### olist_sellers_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695fefa",
   "metadata": {},
   "source": [
    "Informations sur les vendeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des 5 premières lignes du dataset\n",
    "sellers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape du dataset\n",
    "shape_total_nan(sellers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68446589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description des variables\n",
    "describe_variables(sellers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3095c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublons totaux\n",
    "dblon = sellers.duplicated(subset=['seller_id',\n",
    "                                   'seller_zip_code_prefix']).sum()\n",
    "print(f\"Doublons: {dblon}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed55214",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- aucune valeur manquante\n",
    "- seller_id est la clef qui fait le lien avec le dataset order_items et zip_code_prefix avec le dataset geolocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ca5eb",
   "metadata": {},
   "source": [
    "### product_category_name_translation.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af68f6",
   "metadata": {},
   "source": [
    "Traduction des categories des produits en anglais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6828bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des 5 premières lignes du dataset\n",
    "category.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f251a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape du dataset\n",
    "shape_total_nan(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e6f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description des variables\n",
    "describe_variables(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee567444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublons totaux\n",
    "print(f\"Lignes en doublons: {category.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e007d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Différentes catégories en anglais\n",
    "category['product_category_name_english'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02121207",
   "metadata": {},
   "source": [
    "Il existe 71 catégories que nous allons réaffecter dans de plus grandes catégories pour réduire les modalités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe972682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du dictionnaire des catégories générales\n",
    "BIG_CAT = {\n",
    "    'health_beauty': 'hygiene/beauty',\n",
    "    'computers_accessories': 'electronics',\n",
    "    'auto': 'auto',\n",
    "    'bed_bath_table': 'house/decoration/furnitures',\n",
    "    'furniture_decor': 'house/decoration/furnitures',\n",
    "    'sports_leisure': 'books/culture/leisure',\n",
    "    'perfumery': 'hygiene/beauty',\n",
    "    'housewares': 'house/decoration/furnitures',\n",
    "    'telephony':  'electronics',\n",
    "    'watches_gifts': 'electronics',\n",
    "    'food_drink': 'food',\n",
    "    'baby': 'baby',\n",
    "    'stationery': 'house/decoration/furnitures',\n",
    "    'tablets_printing_image': 'electronics',\n",
    "    'toys': 'toys',\n",
    "    'fixed_telephony': 'electronics',\n",
    "    'garden_tools': 'DoItYourself',\n",
    "    'fashion_bags_accessories': 'fashion/luggage',\n",
    "    'small_appliances': 'electronics',\n",
    "    'consoles_games': 'electronics',\n",
    "    'audio': 'multimedia',\n",
    "    'fashion_shoes': 'fashion/luggage',\n",
    "    'cool_stuff': 'other',\n",
    "    'luggage_accessories': 'fashion/luggage',\n",
    "    'air_conditioning': 'electronics',\n",
    "    'construction_tools_construction': 'DoItYourself',\n",
    "    'kitchen_dining_laundry_garden_furniture': 'house/decoration/furnitures',\n",
    "    'costruction_tools_garden': 'DoItYourself',\n",
    "    'fashion_male_clothing': 'fashion/luggage',\n",
    "    'pet_shop': 'pets',\n",
    "    'office_furniture': 'house/decoration/furnitures',\n",
    "    'market_place': 'other',\n",
    "    'electronics': 'electronics',\n",
    "    'home_appliances': 'electronics',\n",
    "    'party_supplies': 'house/decoration/furnitures',\n",
    "    'home_confort': 'house/decoration/furnitures',\n",
    "    'costruction_tools_tools': 'DoItYourself',\n",
    "    'agro_industry_and_commerce': 'other',\n",
    "    'furniture_mattress_and_upholstery': 'house/decoration/furnitures',\n",
    "    'books_technical': 'books/culture/leisure',\n",
    "    'home_construction': 'DoItYourself',\n",
    "    'musical_instruments': 'music',\n",
    "    'furniture_living_room': 'house/decoration/furnitures',\n",
    "    'construction_tools_lights': 'DoItYourself',\n",
    "    'industry_commerce_and_business': 'other',\n",
    "    'food': 'food',\n",
    "    'art': 'books/culture/leisure',\n",
    "    'furniture_bedroom': 'house/decoration/furnitures',\n",
    "    'books_general_interest': 'books/culture/leisure',\n",
    "    'construction_tools_safety': 'DoItYourself',\n",
    "    'fashion_underwear_beach': 'fashion/luggage',\n",
    "    'fashion_sport': 'fashion/luggage',\n",
    "    'signaling_and_security': 'other',\n",
    "    'computers': 'electronics',\n",
    "    'christmas_supplies': 'house/decoration/furnitures',\n",
    "    'fashio_female_clothing': 'fashion/luggage',\n",
    "    'home_appliances_2': 'electronics',\n",
    "    'books_imported': 'books/culture/leisure',\n",
    "    'drinks': 'food',\n",
    "    'cine_photo': 'books/culture/leisure',\n",
    "    'la_cuisine': 'books/culture/leisure',\n",
    "    'music': 'music',\n",
    "    'home_comfort_2': 'house/decoration/furnitures',\n",
    "    'small_appliances_home_oven_and_coffee': 'electronics',\n",
    "    'cds_dvds_musicals': 'multimedia',\n",
    "    'dvds_blu_ray': 'multimedia',\n",
    "    'flowers': 'house/decoration/furnitures',\n",
    "    'arts_and_craftmanship': 'books/culture/leisure',\n",
    "    'diapers_and_hygiene': 'hygiene/beauty',\n",
    "    'fashion_childrens_clothes': 'fashion/luggage',\n",
    "    'security_and_services': 'other'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ffeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "category[\"Big_Categ\"] = detect_words(category[\"product_category_name_english\"],\n",
    "                                     BIG_CAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71c6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "category[\"Big_Categ\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b94184",
   "metadata": {},
   "outputs": [],
   "source": [
    "category.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee7c05",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- aucune valeur manquante\n",
    "- une catégorie plus large avec moins de modalités a été crééé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94319b3a",
   "metadata": {},
   "source": [
    "## Consolidation des données (par order_id) <a class=\"anchor\" id=\"conso\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924340e7",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96260c97",
   "metadata": {},
   "source": [
    "Dans cette partie nous allons relier les différents datasets entre-eux en se basant sur le schéma des données. Nous nous assurons à chaque jointure qu'il y a bien une ligne par commande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a770c821",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge orders avec customers\n",
    "df_conso = pd.merge(left=orders, right=customers[['customer_id',\n",
    "                                                  'customer_unique_id',\n",
    "                                                  'customer_zip_code_prefix']],\n",
    "                    how='left', on='customer_id')\n",
    "shape_total_nan(df_conso)\n",
    "df_conso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6733f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge avec geo\n",
    "df_conso = pd.merge(left=df_conso,\n",
    "                    right=geo[['geolocation_zip_code_prefix',\n",
    "                               'zone',\n",
    "                               'geolocation_lat',\n",
    "                               'geolocation_lng']],\n",
    "                    how='left',\n",
    "                    left_on='customer_zip_code_prefix',\n",
    "                    right_on='geolocation_zip_code_prefix')\n",
    "\n",
    "df_conso.drop(columns=['customer_zip_code_prefix',\n",
    "                       'geolocation_zip_code_prefix'], inplace=True)\n",
    "\n",
    "df_conso.rename(columns={'geolocation_lat': 'customer_lat',\n",
    "                         'geolocation_lng': 'customer_lon',\n",
    "                         'zone': 'customer_zone'}, inplace=True)\n",
    "\n",
    "shape_total_nan(df_conso)\n",
    "\n",
    "df_conso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c8faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge orders avec reviews\n",
    "df_conso = pd.merge(left=df_conso, right=reviews, how='left', on='order_id')\n",
    "shape_total_nan(df_conso)\n",
    "df_conso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1cd54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge avec payments\n",
    "df_conso = pd.merge(left=df_conso, right=payments_merge,\n",
    "                    how='left', on='order_id')\n",
    "shape_total_nan(df_conso)\n",
    "df_conso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge avec order_items\n",
    "df_conso = pd.merge(left=df_conso, right=items_merge,\n",
    "                    how='left', on='order_id')\n",
    "shape_total_nan(df_conso)\n",
    "df_conso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d009103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge avec products\n",
    "products_merge.rename(columns={'product_id': 'art_pref'},\n",
    "                      inplace=True)\n",
    "df_conso = pd.merge(left=df_conso, right=products_merge,\n",
    "                    how='left', on='art_pref')\n",
    "df_conso.rename(columns={'product_category_name': 'cat_pref'},\n",
    "                inplace=True)\n",
    "shape_total_nan(df_conso)\n",
    "df_conso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0567696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge avec category_name\n",
    "category.rename(columns={'product_category_name': 'cat_pref',\n",
    "                         'product_category_name_english': 'cat_pref_en',\n",
    "                         'Big_Categ': 'Big_Categ_pref'},\n",
    "                inplace=True)\n",
    "df_conso = pd.merge(left=df_conso, right=category, how='left',\n",
    "                    on='cat_pref')\n",
    "shape_total_nan(df_conso)\n",
    "df_conso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b87da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge avec sellers\n",
    "sellers.rename(columns={'seller_id': 'vendeur_pref'},\n",
    "               inplace=True)\n",
    "df_conso = pd.merge(left=df_conso, right=sellers[['vendeur_pref',\n",
    "                                                  'seller_zip_code_prefix']],\n",
    "                    how='left', on='vendeur_pref')\n",
    "shape_total_nan(df_conso)\n",
    "df_conso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b8068",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merge avec geo\n",
    "df_conso = pd.merge(left=df_conso,\n",
    "                    right=geo[['geolocation_zip_code_prefix',\n",
    "                               'zone',\n",
    "                               'geolocation_lat',\n",
    "                               'geolocation_lng']],\n",
    "                    how='left',\n",
    "                    left_on='seller_zip_code_prefix',\n",
    "                    right_on='geolocation_zip_code_prefix')\n",
    "\n",
    "df_conso.drop(columns=['seller_zip_code_prefix',\n",
    "                       'geolocation_zip_code_prefix'], inplace=True)\n",
    "\n",
    "df_conso.rename(columns={'geolocation_lat': 'seller_lat',\n",
    "                         'geolocation_lng': 'seller_lon',\n",
    "                         'zone': 'seller_zone'}, inplace=True)\n",
    "\n",
    "shape_total_nan(df_conso)\n",
    "\n",
    "df_conso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854bd605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification que la table contient bien une ligne par commande\n",
    "df_conso.shape[0] == df_conso['order_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d03a94",
   "metadata": {},
   "source": [
    "### Création de nouveaux indicateurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec324e5f",
   "metadata": {},
   "source": [
    "Nous allons créer dans ce dataset consolidé d'autres indicateurs qui nous paraissent importants:\n",
    "- durée de la livraison en jours entre la date où le client a passé commande et la date réelle de livraison \n",
    "- différence en jours entre la date estimée de livraison et la date réelle de livraison\n",
    "- temps en jours que met le client avant de rédiger un commentaire à partir du moment où il reçoit le lien\n",
    "- si la commande a été livrée (on supprimera les commandes non encore livrées)\n",
    "- distance entre le vendeur et le client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372aca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation des dates au format datetime\n",
    "df_conso['order_purchase_timestamp'] = pd.to_datetime(\n",
    "    df_conso['order_purchase_timestamp'])\n",
    "df_conso['order_delivered_customer_date'] = pd.to_datetime(\n",
    "    df_conso['order_delivered_customer_date'])\n",
    "df_conso['order_estimated_delivery_date'] = pd.to_datetime(\n",
    "    df_conso['order_estimated_delivery_date'])\n",
    "df_conso['review_creation_date'] = pd.to_datetime(\n",
    "    df_conso['review_creation_date'])\n",
    "df_conso['review_answer_timestamp'] = pd.to_datetime(\n",
    "    df_conso['review_answer_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9726e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des indicateurs\n",
    "df_conso['dur_livr_jrs'] = (df_conso[\n",
    "    'order_delivered_customer_date'] - df_conso[\n",
    "    'order_purchase_timestamp']).dt.days\n",
    "\n",
    "df_conso['diff_estime_livr_jrs'] = (df_conso[\n",
    "    'order_estimated_delivery_date'] - df_conso[\n",
    "    'order_delivered_customer_date']).dt.days\n",
    "\n",
    "df_conso['redac_com_jrs'] = (df_conso[\n",
    "    'review_answer_timestamp'] - df_conso[\n",
    "    'review_creation_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba35d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commande livrée ou non\n",
    "df_conso.loc[df_conso['dur_livr_jrs'].isna(), 'com_livree'] = 0\n",
    "df_conso.loc[~df_conso['dur_livr_jrs'].isna(), 'com_livree'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c456bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des commandes non livrées\n",
    "com_non_livrees = df_conso[df_conso['com_livree'] == 0]['order_id'].nunique()\n",
    "print(f\"Commandes non livrées: {com_non_livrees}\")\n",
    "df_conso = df_conso[df_conso['com_livree'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui calcule la distance\n",
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    newlon = lon2 - lon1\n",
    "    newlat = lat2 - lat1\n",
    "\n",
    "    haversine_formula = np.sin(\n",
    "        newlat/2.0)**2 + np.cos(\n",
    "        lat1) * np.cos(\n",
    "        lat2) * np.sin(\n",
    "        newlon/2.0)**2\n",
    "\n",
    "    dist = 2 * np.arcsin(np.sqrt(haversine_formula))\n",
    "    km = 6367 * dist\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf227ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calcul de la distance entre le client et le vendeur\n",
    "df_conso['distance_km'] = haversine_distance(df_conso['seller_lon'],\n",
    "                                             df_conso['seller_lat'],\n",
    "                                             df_conso['customer_lon'],\n",
    "                                             df_conso['customer_lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c10f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des colonnes non utilisées\n",
    "df_conso.drop(columns=['order_status',\n",
    "                       'order_approved_at',\n",
    "                       'order_delivered_carrier_date',\n",
    "                       'order_delivered_customer_date',\n",
    "                       'order_estimated_delivery_date',\n",
    "                       'customer_lat',\n",
    "                       'customer_lon',\n",
    "                       'review_id',\n",
    "                       'review_comment_title',\n",
    "                       'review_comment_message',\n",
    "                       'review_creation_date',\n",
    "                       'review_answer_timestamp',\n",
    "                       'art_pref',\n",
    "                       'vendeur_pref',\n",
    "                       'cat_pref',\n",
    "                       'seller_lat',\n",
    "                       'seller_lon',\n",
    "                       'com_livree'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81e0df7",
   "metadata": {},
   "source": [
    "### Données manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4692d03",
   "metadata": {},
   "source": [
    "Le nombre de lignes avec données manquantes étant relativement faible, nous décidons de les supprimer au lieu de rajouter du bruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578fd868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre et % de NaN\n",
    "\n",
    "def NaN_nb_percent(df):\n",
    "    '''Fonction qui retourne le taux de remplissage et\n",
    "    le nombre de valeurs manquantes de chaque variable du dataset.'''\n",
    "\n",
    "    var_dict = {}\n",
    "\n",
    "    for c in df.columns:\n",
    "        var_dict[c] = []\n",
    "        var_dict[c].append(round((df[c].notna().sum()/df.shape[0])*100, 2))\n",
    "        var_dict[c].append(df[c].isna().sum())\n",
    "\n",
    "    return pd.DataFrame.from_dict(\n",
    "        data=var_dict,\n",
    "        orient='index',\n",
    "        columns=['Tx de remplissage', 'Nb NaN']).sort_values(\n",
    "        by='Nb NaN', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6fc3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taux de remplissage des colonnes\n",
    "nan = NaN_nb_percent(df_conso)\n",
    "nan[nan['Nb NaN'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c8290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des lignes avec au moins un NaN\n",
    "df_conso.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734ece8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_conso.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a11da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression de variables\n",
    "del geo_dup\n",
    "del orders\n",
    "del reviews\n",
    "del items\n",
    "del payments\n",
    "del customers\n",
    "del products\n",
    "del items_dup\n",
    "del geo\n",
    "del customers_orders\n",
    "del zip_city\n",
    "del zip_mean\n",
    "del payments_dup\n",
    "del sellers\n",
    "del reviews_dup\n",
    "del order_id_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f377ed",
   "metadata": {},
   "source": [
    "### Analyse univariée par commande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89245c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "describe_variables(df_conso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7435cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Période analysée\n",
    "print(df_conso['order_purchase_timestamp'].min())\n",
    "print(df_conso['order_purchase_timestamp'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03704499",
   "metadata": {},
   "source": [
    "La période s'étend du 3/10/2016 au 29/08/2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cf7613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def univ_plots_hist(dataframe, liste_col_quanti, nb_lignes, nb_col, nb_bins):\n",
    "\n",
    "    for i, c in enumerate(liste_col_quanti, 1):\n",
    "        ax = fig.add_subplot(nb_lignes, nb_col, i)\n",
    "        ax.hist(dataframe[c], bins=nb_bins, color='#b8b8d2')\n",
    "        ax.set_title(c, fontsize=10)\n",
    "        ax.title.set_fontweight('bold')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    plt.tight_layout(w_pad=2, h_pad=2)\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8b58ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_quanti = ['review_score', 'facil_paiement_max', 'nb_art', 'nb_art_diff',\n",
    "              'nb_vendeurs', 'prix_tot_art',\n",
    "              'prix_transport', 'prix_art_min', 'prix_art_max',\n",
    "              'dur_livr_jrs', 'diff_estime_livr_jrs', 'redac_com_jrs',\n",
    "              'distance_km']\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "univ_plots_hist(df_conso, col_quanti, 4, 4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ba454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_plots_box(dataframe, liste_col_quanti, nb_lignes, nb_col):\n",
    "    for i, c in enumerate(liste_col_quanti, 1):\n",
    "        ax = fig.add_subplot(nb_lignes, nb_col, i)\n",
    "        ax = sns.boxplot(data=dataframe, x=c, showfliers=True,\n",
    "                         color='#b8b8d2')\n",
    "        ax.set_title(c)\n",
    "        ax.title.set_fontweight('bold')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    plt.tight_layout(w_pad=2, h_pad=2)\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c04d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "univariate_plots_box(df_conso, col_quanti, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed6c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_plots_quali(dataframe, liste_col_quali, nb_lignes, nb_col):\n",
    "    for i, c in enumerate(liste_col_quali, 1):\n",
    "        ax = fig.add_subplot(nb_lignes, nb_col, i)\n",
    "        modalites = dataframe[c].value_counts()\n",
    "        n_modalites = modalites.shape[0]\n",
    "\n",
    "        if n_modalites > 15:\n",
    "            modalites[0:15].plot.bar(color='#b8b8d2', edgecolor='black', ax=ax)\n",
    "\n",
    "        else:\n",
    "            modalites.plot.bar(color='#b8b8d2', edgecolor='black')\n",
    "\n",
    "        ax.set_title(f'{c} ({n_modalites} modalités)',\n",
    "                     fontweight='bold',\n",
    "                     fontsize=10)\n",
    "        labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "        short_labels = [lab[0:7] + '.' if len(lab) > 7\n",
    "                        else lab for lab in labels]\n",
    "        ax.axes.set_xticklabels(short_labels)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    plt.tight_layout(w_pad=2, h_pad=2)\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd7760",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_quali = ['customer_zone', 'seller_zone', 'moy_paiement_pref',\n",
    "             'Big_Categ_pref', 'cat_pref_en']\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "univariate_plots_quali(df_conso, col_quali, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cefd360",
   "metadata": {},
   "source": [
    "- Les clients notent plutôt favorablement lorsqu'ils passent une commande avec une majorité de 5/5\n",
    "- Le montant des commandes est généralement peu élevé avec un montant moyen par commande de 137 Réals + 27 Réals de livraison\n",
    "- Le nombre de facilités de paiement tourne autour de 3 en moyenne mais peuvent être beaucoup plus important\n",
    "- La majorité des clients sélectionne un article par commande\n",
    "- Il y a en général un vendeur unique par commande\n",
    "- Il faut 12 jours en moyenne au client pour être livré\n",
    "- Il y a en général 11 jours de retard dans les livraisons mais parfois le livreur est en avance\n",
    "- Le client met 2 jours et demi en moyenne par commande pour rédiger un commentaire\n",
    "- Les vendeurs se situent en moyenne à 600 km du client\n",
    "- La majorité des commandes sont passées par des clients basés dans le Sud Est du Brésil\n",
    "- La majorité des vendeurs se situe également dans le Sud Est\n",
    "- Les clients paient majoritairement par carte de crédit\n",
    "- Les produits les plus commandés sont les produits de maison/décoration/fournitures puis l'électronique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd1b3bc",
   "metadata": {},
   "source": [
    "### Analyse bivariée / multivariée par commande"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc0699a",
   "metadata": {},
   "source": [
    "#### Variables quantitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0955c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrélation\n",
    "corr = df_conso[col_quanti].corr()\n",
    "\n",
    "# Création d'un masque\n",
    "mask = np.triu(corr)\n",
    "\n",
    "# Taille du graph\n",
    "plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Heatmap avec masque\n",
    "sns.heatmap(corr, annot=True, mask=mask, cmap=cmap)\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "plt.title(\"Matrice de corrélation entre les variables quantitatives\\n\",\n",
    "          fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1ccfd4",
   "metadata": {},
   "source": [
    "- La note attribuée à la commande est corrélée aux nombre de jours de retard de livraison et au nombre de jours de livraison\n",
    "- Le montant total de la commande est corrélé au nombre de facilités de paiement\n",
    "- Le montant du transport est lié au prix de l'article et à la distance entre le client et le vendeur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a866a298",
   "metadata": {},
   "source": [
    "#### Une variable quantitative et une qualitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7323e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "infl_note = ['prix_tot_art', 'prix_transport',\n",
    "             'dur_livr_jrs', 'diff_estime_livr_jrs']\n",
    "\n",
    "fig = plt.figure(figsize=(15, 9))\n",
    "\n",
    "%pycodestyle_off\n",
    "for i, c in enumerate(infl_note, 1):\n",
    "    ax = fig.add_subplot(2, 2, i)\n",
    "    meanprops = {'marker':'o', 'markeredgecolor':'black','markerfacecolor':'firebrick'}\n",
    "    ax = sns.boxplot(data = df_conso, y = c, x = 'review_score',\n",
    "                     showfliers=False,\n",
    "                     showmeans=True,\n",
    "                     meanprops=meanprops)\n",
    "    plt.suptitle('Dispersion des variables quantitatives en fonction de la note', fontsize=16,\n",
    "             fontweight='bold')\n",
    "\n",
    "    ax.title.set_fontweight('bold')\n",
    "    \n",
    "plt.tight_layout(w_pad=2, h_pad=2)\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef360b46",
   "metadata": {},
   "source": [
    "La note associée à la commande semble être surtout liée aux variables en rapport avec la livraison de la commande.\n",
    "Les clients attribuent les meilleures notes lorsque le prix du transport est plus faible, les délais de livraison plus courts, et la date de livraison respectée ou en avance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9ee53",
   "metadata": {},
   "source": [
    "#### Variables qualitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_test(data, var_quali_1, var_quali_2,\n",
    "              palette=sns.color_palette('pastel')):\n",
    "    palette = palette\n",
    "    # Table de contingence\n",
    "    tab_cont = pd.crosstab(data[var_quali_1], data[var_quali_2])\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.title(f'Table de contingence {var_quali_1} / {var_quali_2}',\n",
    "              fontsize=12, fontweight='bold')\n",
    "    sns.heatmap(tab_cont, cmap=\"YlGnBu\", annot=True, cbar=False, fmt=\"d\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.show()\n",
    "    # Diagramme en barres selon les profils colonnes\n",
    "    tab_cont_prop = pd.crosstab(data[var_quali_1], data[var_quali_2],\n",
    "                                normalize=\"index\")\n",
    "    modalites = len(tab_cont.columns)\n",
    "    if modalites <= 5:\n",
    "        with sns.color_palette(palette):\n",
    "            tab_cont_prop.plot(kind='bar', stacked=True,\n",
    "                               figsize=(15, 9), width=0.8)\n",
    "            plt.legend(loc=\"upper left\", ncol=6)\n",
    "            plt.xlabel(var_quali_1)\n",
    "            plt.ylabel(\"Proportion\")\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.title('Diagramme en barres selon les profils colonnes',\n",
    "                      fontsize=12, fontweight='bold')\n",
    "            plt.show()\n",
    "\n",
    "        if len(np.where(tab_cont <= 5)[0]) == 0:\n",
    "            print('Chaque effectif >= 5 => Test du Chi2 applicable')\n",
    "            # Running Chi2 test\n",
    "            print('----------------------------------------------------------')\n",
    "            st_chi2, st_p, st_dof, st_exp = chi2_contingency(tab_cont)\n",
    "            print(f\"Chi2: {st_chi2}\")\n",
    "            print(f\"Degrees of freedom: {st_dof}\")\n",
    "            print('----------------------------------------------------------')\n",
    "            if st_p < 0.05:\n",
    "                print(f\"pvalue: {st_p} < 0.05 => var dépendantes\")\n",
    "            else:\n",
    "                print(f\"pvalue: {st_p} > 0.05 => var indépendantes\")\n",
    "        else:\n",
    "            print(\"Au moins un effectif de la table de contingence < 5\")\n",
    "            print(\"Test du Chi2 d'indépendance\")\n",
    "            # Running Chi2 Independance\n",
    "            print('----------------------------------------------------------')\n",
    "            expected, observed, stat = pg.chi2_independence(data,\n",
    "                                                            var_quali_1,\n",
    "                                                            var_quali_2)\n",
    "            print(stat)\n",
    "            print('----------------------------------------------------------')\n",
    "            if stat['pval'][0] < 0.05:\n",
    "                print(f\"pvalue: {stat['pval'][0]} < 0.05 = >var dépendantes\")\n",
    "            else:\n",
    "                print(f\"pvalue: {stat['pval'][0]} > 0.05 => var indépendantes\")\n",
    "    else:\n",
    "        if len(np.where(tab_cont <= 5)[0]) == 0:\n",
    "            print('Chaque effectif de la table de contingence >= 5')\n",
    "            print('Test du Chi2 applicable')\n",
    "            # Running Chi2 test\n",
    "            print('----------------------------------------------------------')\n",
    "            st_chi2, st_p, st_dof, st_exp = chi2_contingency(tab_cont)\n",
    "            print(f\"Chi2: {st_chi2}\")\n",
    "            print(f\"Degrees of freedom: {st_dof}\")\n",
    "            print('----------------------------------------------------------')\n",
    "            if st_p < 0.05:\n",
    "                print(f\"pvalue: {st_p} < 0.05 => var dépendantes\")\n",
    "            else:\n",
    "                print(f\"pvalue: {st_p} > 0.05 => var indépendantes\")\n",
    "        else:\n",
    "            print(\"Au moins un effectif de la table de contingence < 5\")\n",
    "            print(\"Test du Chi2 d'indépendance\")\n",
    "            # Running Chi2 Independance\n",
    "            print('----------------------------------------------------------')\n",
    "            expected, observed, stat = pg.chi2_independence(data,\n",
    "                                                            var_quali_1,\n",
    "                                                            var_quali_2)\n",
    "            print(stat)\n",
    "            print('----------------------------------------------------------')\n",
    "            if stat['pval'][0] < 0.05:\n",
    "                print(f\"pvalue: {stat['pval'][0]} < 0.05 => var dépendantes\")\n",
    "            else:\n",
    "                print(f\"pvalue: {stat['pval'][0]} > 0.05 => var indépendantes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7e64d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_test(df_conso, 'Big_Categ_pref', 'review_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c251bd5",
   "metadata": {},
   "source": [
    "Le test du Chi2 confirme l'hypothèse d'association entre les variables Big_Categ_pref et review_score.\n",
    "\n",
    "Les meilleures notes semblent être attribuées aux aliments, musique, animaux et jouets et les moins bonnes aux catégories multimédia, maison/décoration, électronique etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd460f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_test(df_conso, 'moy_paiement_pref', 'review_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a395cf1",
   "metadata": {},
   "source": [
    "Le test du Chi2 confirme l'hypothèse d'association entre les variables moy_paiement_pref et review_score. Cependant, la visualisation du diagramme en barres selon les profils colonnes ne nous laisse pas vraiment penser que la satisfaction dépende du moyen de paiement préféré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4fbc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_test(df_conso, 'customer_zone', 'review_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf76b4",
   "metadata": {},
   "source": [
    "Le test du Chi2 confirme l'hypothèse d'association entre les variables customer_zone et review_score. Les clients du centre est, nord et nord est semblent plus mécontents que les clients du sud et nord ouest par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc424b8d",
   "metadata": {},
   "source": [
    "## Consolidation des données (par customer_unique_id) <a class=\"anchor\" id=\"tab_cli\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7e832a",
   "metadata": {},
   "source": [
    "Le customer_unique_id représente l'identifiant client pour toutes les commandes. Nous allons passer par la table intermédiaire sur les commandes pour pouvoir calculer les indicateurs aggrégés suivants par **client** (dont les indicateurs RFM utilisés fréquemment dans les segmentations marketing: **Recency** (jours passés depuis le dernier achat), **Frequency** (nombre total de commandes) et **Monetary** (montant total dépensé)):\n",
    "- catégorie de produits la plus achetée\n",
    "- date de la dernière commande (nous calculerons ensuite la différence en jours avec la date du jour pour obtenir la **Recency**)\n",
    "- mode de paiement préféré\n",
    "- nombre total de commandes (**Frequency**)\n",
    "- note moyenne des commandes\n",
    "- nombre moyen de facilités de paiement\n",
    "- nombre d'articles moyens par commande\n",
    "- nombre d'articles achetés\n",
    "- nombre d'articles différents achetés\n",
    "- montant total dépensé (**Monetary**)\n",
    "- montant moyen par commande\n",
    "- prix moyen du transport\n",
    "- prix moyen des articles par commande\n",
    "- prix de l'article le plus cher acheté\n",
    "- prix de l'article le moins cher acheté\n",
    "- durée moyenne de livraison en jours\n",
    "- respect de la date de livraison moyenne en jour (négatif = retard de livraison et positif = avance de livraison)\n",
    "- nombre de jours moyens pour rédiger un commentaire\n",
    "- distance moyenne entre le client et le vendeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc0f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers = df_conso.groupby(['customer_unique_id'],\n",
    "                                as_index=False, dropna=False).agg(\n",
    "    cat_pref=('cat_pref_en', lambda x: x.mode()[0]),\n",
    "    big_cat_pref=('Big_Categ_pref', lambda x: x.mode()[0]),\n",
    "    date_dern_com=('order_purchase_timestamp', 'max'),\n",
    "    moy_paiement_pref=('moy_paiement_pref', lambda x: x.mode()[0]),\n",
    "    Frequency=('order_id', 'nunique'),\n",
    "    note_moy_com=('review_score', 'mean'),\n",
    "    facil_paiement_max_moy_com=('facil_paiement_max', 'mean'),\n",
    "    nb_art_moy_com=('nb_art', 'mean'),\n",
    "    nb_art_tot_ach=('nb_art', 'sum'),\n",
    "    nb_art_diff_ach=('nb_art_diff', 'sum'),\n",
    "    Monetary=('prix_tot_art', 'sum'),\n",
    "    montant_moy_com=('prix_tot_art', 'mean'),\n",
    "    prix_trans_moy_com=('prix_transport', 'mean'),\n",
    "    prix_moy_art_com=('prix_tot_art', 'mean'),\n",
    "    prix_max_art=('prix_art_max', 'max'),\n",
    "    prix_min_art=('prix_art_min', 'min'),\n",
    "    jrs_livr_moy_com=('dur_livr_jrs', 'mean'),\n",
    "    respect_date_livr_moy_com=('diff_estime_livr_jrs', 'mean'),\n",
    "    jrs_redac_review_moy_com=('redac_com_jrs', 'mean'),\n",
    "    dist_cli_vend_moy_km=('distance_km', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8afc1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création table avec la Zone la plus récente du client\n",
    "tab_zone_cli = df_conso.groupby(['customer_unique_id', 'customer_zone'],\n",
    "                                as_index=False, dropna=False).agg(\n",
    "    order_purchase_timestamp=('order_purchase_timestamp', 'max')).sort_values(\n",
    "    by='order_purchase_timestamp', ascending=False)\n",
    "\n",
    "# Nombre de lignes ayant le même customer_unique_id\n",
    "print(f\"Nb lignes: {tab_zone_cli.duplicated('customer_unique_id').sum()}\")\n",
    "\n",
    "# On converve la zone la plus récente\n",
    "tab_zone_cli = tab_zone_cli.drop_duplicates('customer_unique_id',\n",
    "                                            keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec5c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout de la zone la plus récente du client\n",
    "df_customers = pd.merge(left=df_customers, right=tab_zone_cli,\n",
    "                        how='left', on='customer_unique_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba3c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification que la table contient bien une ligne par client\n",
    "df_customers.shape[0] == df_conso['customer_unique_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb66fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date de commande la plus récente:\n",
    "df_customers['date_dern_com'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0366f8",
   "metadata": {},
   "source": [
    "Nous allons calculer la \"Recency\" en partant du principe que nous sommes le 31/08/2018, 23h59."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da0f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la \"Recency\"\n",
    "now = dt.datetime(year=2018, month=8, day=31, hour=23, minute=59, second=0)\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91bc143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers['Recency'] = (now - df_customers[\n",
    "    'date_dern_com']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df3fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9669c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taux de remplissage des colonnes\n",
    "NaN_nb_percent(df_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445a31d3",
   "metadata": {},
   "source": [
    "### Analyse des indicateurs RFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfed67e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "describe_variables(df_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16865cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_quanti = ['Recency', 'Frequency', 'Monetary']\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "univ_plots_hist(df_customers, col_quanti, 1, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "univariate_plots_box(df_customers, col_quanti, 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c38f5d3",
   "metadata": {},
   "source": [
    "- Le nombre de jours passés depuis le dernier achat se situe entre 2 et près de 700 jours avec une moyenne de 239 jours et une médiane de 219 jours\n",
    "- Les clients effectuent 1 commande en moyenne avec un maximum de 14 commandes\n",
    "- Les clients ont dépensé en moyenne 141 Réals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f8bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des clients ayant passé plusieurs commandes\n",
    "cli_multi_order = df_customers[df_customers['Frequency'] > 1]\n",
    "cli_multi_order = cli_multi_order['customer_unique_id'].unique().tolist()\n",
    "\n",
    "# % de clients ayant passé plusieurs commandes\n",
    "nb_cli_multi = len(cli_multi_order)\n",
    "nb_cli = df_customers['customer_unique_id'].nunique()\n",
    "nb_cli_multi_percent = nb_cli_multi / nb_cli * 100\n",
    "print(f\"% clients avec plusieurs commandes {round(nb_cli_multi_percent,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7081bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cli_multi_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a708215d",
   "metadata": {},
   "source": [
    "On retombe bien sur les 3% de clients indiqués dans l'énoncé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9622b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export des données\n",
    "df_customers.to_csv('data/df_customers.csv')\n",
    "df_conso.to_csv('data/df_conso.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet5",
   "language": "python",
   "name": "projet5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": "30",
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "855.85px",
    "left": "2009px",
    "right": "20px",
    "top": "116px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
